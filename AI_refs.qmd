---
title: "AI Policy"
format:
  html: default
  pdf:
    toc: true
    number-sections: true
    colorlinks: true
---

:::::: columns
::: {.column width="45%"}
So I'm not an expert in how humans learn, but I have been teaching mathematics for more than 25 years so I have some ideas.  In my experience (and there is research to back this up) we learn best when we are **actively** engaged with the process.  We need to make mistakes, guesses, conjectures.  We need to struggle a bit to make sense of what we're doing. This is the realm of what some educators call *productive discomfort*.  


Not only is it *okay* to be stuck, to be confused, but this is actually to be *desired* becuase this is what leads to authentic learning.

My job is to guide you through that journey - to challenge you just enough that you are in that zone while at the same time, provide guidance when needed so that you're never overwhelmed.

"But I don't want to feel uncomfortable!" I hear you say.  Sure, I get it.  But I have to ask -- why are you here if not to learn, to grow, to challenge yourself?  Part of my job is to help create, with your help, a learning environment where you feel safe to make mistakes.  So while a well constructed lecture *feels* comfortable - it's simply not as effective as constructing your own understanding.  


:::

::: {.column width="5%"}
:::

::: {.column width="50%"}
![](./images/sousanis.jpg)
:::
::::::

The AI policy in this class is don't use it.

First, to clarify --  when I refer to AI here, I'm specifically thinking of generative AI tools such as 
ChatGPT -- also known as large language models (LLMs). 

With regard to the use of AI tools in this course, there are two types of usage we can think of.

Here are a few reasons behind my thinking...

-   Generative AI tools are [Bullshit Machines](https://thebullshitmachines.com/) in the sense that they are designed to produce output that sounds convincing -- *without regard to whether their output is true or not*.  If you're using an AI tool to help with mathematics, you can't be certain that the output is correct.

-   Now it's true that all the material in this class has been written down in hundreds (thousands?) of textbooks, which have all been used to train these LLMs (without their author's permission).  This means that if you're asking an AI tool about a calculus problem or concept, it most likely will give you correct information. But maybe not, which means you need to still need to check it yourself.

-   What about using AI tools to help explain a concept or technique that you find confusing? Here's the problem I see with this – the mental struggle of trying to make sense of a new, hard thing is **precisely the point**\*\*. If you off-load that, you aren't really engaging with the material in a way that is going to lead to authentic learning. There is reason that my classes don't have much lecturing in them – that's not a great way to learn. Many students think

-   



I am not interested in policing you or participating in a [surveillance](https://thehill.com/opinion/technology/4319035-ai-is-supercharging-child-surveillance-and-the-school-to-prison-pipeline/) [structure](https://ojs.library.queensu.ca/index.php/surveillance-and-society/article/view/16105) that claims to "detect" AI-produced material

creating a hostile dynamic between you and your instructor. College is a time for you to decide who you want to be, how you want to engage the work, and take some degree of control. We will discuss this more in class.

Note that this AI policy applies only to this course. For your other courses, please follow those professors' AI policies, which may differ from mine.

### 

Students tell me that they use AI to do "explain" things or check answers. The problem is that LLMs like ChatGPT are **explicitly designed** to sound authoritative, to sound correct. That doesn't mean it is correct -- so if you're using AI to explain something you should be asking yourself how you know whether it's correct.

Q. What about using AI to brainstorm or summarize ideas?

A. That's what your brain is for. Seriously, a significant way in which we can engage with the course content is to embrace the mental struggle of organizing and making sense of ideas. When we use words like "brainstorm" we sometimes think that this isn't the important part. In fact, it's a critical step in learning. Offloading

Q. Can I use AI to check my answers?\
A. How do you know that what your AI-bot tells you is correct? Maybe it is - maybe not.

I will assume that any work that you submit for this class was generated without the use of GenAI.

> Critics have already written thoroughly about the [environmental](https://www.teenvogue.com/story/chatgpt-is-everywhere-environmental-costs-oped) [harms](https://www.bbc.com/news/articles/cy8gy7lv448o), the [reinforcement](https://apnews.com/article/ai-artificial-intelligence-health-business-90020cdf5fa16c79ca2e5b6c4c9bbb14) of [bias](https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/) and generation of [racist output](https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-antisemitic-racist-content), the [cognitive harms](https://www.bloomberg.com/news/articles/2025-08-12/ai-eroded-doctors-ability-to-spot-cancer-within-months-in-study?embedded-checkout=true) and [AI supported suicides](https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html), the problems with [consent](https://www.404media.co/deepfake-harassment-ohio-undress-clothoff-nudify-apps/) and [copyright](https://jskfellows.stanford.edu/theft-is-not-fair-use-474e11f0d063), the way AI tech companies further the [patterns of empire](https://karendhao.com/), how [it's a con](https://thecon.ai/) that enables [fraud](https://voiceofsandiego.org/2025/04/14/as-bot-students-continue-to-flood-in-community-colleges-struggle-to-respond/) and [disinformation](https://www.technologyreview.com/2023/10/04/1080801/generative-ai-boosting-disinformation-and-propaganda-freedom-house/) and [harassment](https://www.reuters.com/world/us/fbi-says-artificial-intelligence-being-used-sextortion-harassment-2023-06-07/) and [surveillance](https://www.aclu.org/news/privacy-technology/machine-surveillance-is-being-super-charged-by-large-ai-models), the [exploitation of workers](https://www.wired.com/story/millions-of-workers-are-training-ai-models-for-pennies/), as an [excuse to fire workers](https://www.theverge.com/news/688679/amazon-ceo-andy-jassy-ai-efficiency) and de-skill work, how they [don't actually reason](https://machinelearning.apple.com/research/illusion-of-thinking) and probability and association are [inadequate to the goal of intelligence](https://thegradient.pub/machine-learning-wont-solve-the-natural-language-understanding-challenge/), how people think it makes them faster when it [makes them slower](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/), how it is inherently mediocre and fundamentally conservative, how it is at its core a [fascist technology](https://newsocialist.org.uk/transmissions/ai-the-new-aesthetics-of-fascism/) rooted in the [ideology of supremacy](https://aworkinglibrary.com/writing/toolmen), defined not by its technical features but [by its political ones](https://ali-alkhatib.com/blog/defining-ai).
>
> \- Anthony Moser, ["I Am An AI Hater"](https://anthonymoser.github.io/writing/ai/haterdom/2025/08/26/i-am-an-ai-hater.html)
